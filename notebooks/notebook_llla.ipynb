{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdefdf5-2a0a-4ca7-9672-7e1544aad8a1",
   "metadata": {
    "id": "1fdefdf5-2a0a-4ca7-9672-7e1544aad8a1"
   },
   "source": [
    "# ğŸ§™â€â™‚ï¸ Sample Generation with Pretrained Model + LLLA\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Jac-Zac/PML_DL_Final_Project/blob/master/notebooks/notebook_llla.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5LsZiP4Jfsqw",
   "metadata": {
    "id": "5LsZiP4Jfsqw"
   },
   "source": [
    "### Initial setup âš™ï¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036ebd6a-207e-4e58-9e53-8eb656a61957",
   "metadata": {},
   "source": [
    "### If runned locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c880eaf-d325-40af-8b9a-a965d417023e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jaczac/Github/PML_DL_Final_Project\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hjV2GS6MlwQP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hjV2GS6MlwQP",
    "outputId": "05770d65-9ea7-4cea-ee2c-d5b84c970d7c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Collecting laplace-torch\n",
       "  Downloading laplace_torch-0.2.2.2-py3-none-any.whl.metadata (5.1 kB)\n",
       "Collecting asdfghjkl==0.1a4 (from laplace-torch)\n",
       "  Downloading asdfghjkl-0.1a4-py3-none-any.whl.metadata (3.2 kB)\n",
       "Collecting backpack-for-pytorch (from laplace-torch)\n",
       "  Downloading backpack_for_pytorch-1.7.1-py3-none-any.whl.metadata (4.4 kB)\n",
       "Collecting curvlinops-for-pytorch>=2.0 (from laplace-torch)\n",
       "  Downloading curvlinops_for_pytorch-2.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
       "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from laplace-torch) (2.0.2)\n",
       "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from laplace-torch) (3.4.0)\n",
       "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from laplace-torch) (2.6.0+cu124)\n",
       "Collecting torchmetrics (from laplace-torch)\n",
       "  Downloading torchmetrics-1.7.3-py3-none-any.whl.metadata (21 kB)\n",
       "Requirement already satisfied: torchvision>=0.15 in /usr/local/lib/python3.11/dist-packages (from laplace-torch) (0.21.0+cu124)\n",
       "Requirement already satisfied: scipy<2.0.0,>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from curvlinops-for-pytorch>=2.0->laplace-torch) (1.15.3)\n",
       "Collecting numpy (from laplace-torch)\n",
       "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
       "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.61.0 in /usr/local/lib/python3.11/dist-packages (from curvlinops-for-pytorch>=2.0->laplace-torch) (4.67.1)\n",
       "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from curvlinops-for-pytorch>=2.0->laplace-torch) (0.8.1)\n",
       "Collecting einconv (from curvlinops-for-pytorch>=2.0->laplace-torch)\n",
       "  Downloading einconv-0.1.0-py3-none-any.whl.metadata (1.9 kB)\n",
       "Collecting unfoldNd<1.0.0,>=0.2.0 (from backpack-for-pytorch->laplace-torch)\n",
       "  Downloading unfoldNd-0.2.3-py3-none-any.whl.metadata (1.5 kB)\n",
       "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (3.18.0)\n",
       "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (4.14.0)\n",
       "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (3.5)\n",
       "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (3.1.6)\n",
       "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (2025.3.2)\n",
       "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->laplace-torch)\n",
       "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
       "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->laplace-torch)\n",
       "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
       "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->laplace-torch)\n",
       "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
       "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->laplace-torch)\n",
       "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
       "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->laplace-torch)\n",
       "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
       "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->laplace-torch)\n",
       "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
       "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->laplace-torch)\n",
       "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
       "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->laplace-torch)\n",
       "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
       "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->laplace-torch)\n",
       "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
       "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (0.6.2)\n",
       "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (2.21.5)\n",
       "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (12.4.127)\n",
       "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->laplace-torch)\n",
       "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
       "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (3.2.0)\n",
       "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->laplace-torch) (1.13.1)\n",
       "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->laplace-torch) (1.3.0)\n",
       "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.15->laplace-torch) (11.2.1)\n",
       "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics->laplace-torch) (24.2)\n",
       "Collecting lightning-utilities>=0.8.0 (from torchmetrics->laplace-torch)\n",
       "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
       "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics->laplace-torch) (75.2.0)\n",
       "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->laplace-torch) (3.0.2)\n",
       "Downloading laplace_torch-0.2.2.2-py3-none-any.whl (77 kB)\n",
       "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hDownloading asdfghjkl-0.1a4-py3-none-any.whl (89 kB)\n",
       "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hDownloading curvlinops_for_pytorch-2.0.1-py3-none-any.whl (67 kB)\n",
       "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.4/67.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hDownloading backpack_for_pytorch-1.7.1-py3-none-any.whl (196 kB)\n",
       "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.6/196.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
       "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
       "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
       "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
       "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
       "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
       "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
       "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
       "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
       "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
       "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
       "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hDownloading torchmetrics-1.7.3-py3-none-any.whl (962 kB)\n",
       "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m962.6/962.6 kB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
       "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
       "Downloading unfoldNd-0.2.3-py3-none-any.whl (16 kB)\n",
       "Downloading einconv-0.1.0-py3-none-any.whl (27 kB)\n",
       "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, unfoldNd, torchmetrics, einconv, asdfghjkl, backpack-for-pytorch, curvlinops-for-pytorch, laplace-torch\n",
       "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
       "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
       "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
       "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
       "  Attempting uninstall: nvidia-curand-cu12\n",
       "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
       "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
       "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
       "  Attempting uninstall: nvidia-cufft-cu12\n",
       "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
       "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
       "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
       "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
       "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
       "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
       "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
       "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
       "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
       "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
       "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
       "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
       "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
       "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
       "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
       "  Attempting uninstall: nvidia-cublas-cu12\n",
       "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
       "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
       "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
       "  Attempting uninstall: numpy\n",
       "    Found existing installation: numpy 2.0.2\n",
       "    Uninstalling numpy-2.0.2:\n",
       "      Successfully uninstalled numpy-2.0.2\n",
       "  Attempting uninstall: nvidia-cusparse-cu12\n",
       "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
       "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
       "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
       "  Attempting uninstall: nvidia-cudnn-cu12\n",
       "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
       "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
       "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
       "  Attempting uninstall: nvidia-cusolver-cu12\n",
       "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
       "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
       "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
       "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
       "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
       "\u001b[0mSuccessfully installed asdfghjkl-0.1a4 backpack-for-pytorch-1.7.1 curvlinops-for-pytorch-2.0.1 einconv-0.1.0 laplace-torch-0.2.2.2 lightning-utilities-0.14.3 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchmetrics-1.7.3 unfoldNd-0.2.3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "e4404408278243dabd6de986afcaedae",
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install laplace-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "qwjhHAHrre1I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qwjhHAHrre1I",
    "outputId": "1b570923-ab8e-49c9-a98a-e3dc22ff5210"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cloning into 'PML_DL_Final_Project'...\n",
       "remote: Enumerating objects: 560, done.\u001b[K\n",
       "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
       "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
       "remote: Total 560 (delta 11), reused 8 (delta 8), pack-reused 542 (from 1)\u001b[K\n",
       "Receiving objects: 100% (560/560), 787.69 KiB | 2.13 MiB/s, done.\n",
       "Resolving deltas: 100% (335/335), done.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "repo_dir = \"PML_DL_Final_Project\"\n",
    "\n",
    "if not os.path.exists(repo_dir):\n",
    "    !git clone https://github.com/Jac-Zac/PML_DL_Final_Project.git\n",
    "else:\n",
    "    print(f\"Repository '{repo_dir}' already exists. Skipping clone.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dSc96RJrokT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5dSc96RJrokT",
    "outputId": "f5cd3567-1dd7-4800-fad0-7427ab8628f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/content/PML_DL_Final_Project\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if os.path.isdir(repo_dir):\n",
    "    %cd $repo_dir\n",
    "    !pip install dotenv -q\n",
    "else:\n",
    "    print(f\"Directory '{repo_dir}' not found. Please clone the repository first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b0bc4-6bf5-40b0-8af7-5c30a02c1ada",
   "metadata": {
    "id": "064b0bc4-6bf5-40b0-8af7-5c30a02c1ada"
   },
   "source": [
    "### ğŸ“¦ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31f6b33e-bec1-47a2-afe0-c57ca840a622",
   "metadata": {
    "id": "31f6b33e-bec1-47a2-afe0-c57ca840a622"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.models.diffusion import Diffusion\n",
    "from src.utils.data import get_dataloaders\n",
    "from src.utils.plots import plot_image_grid, plot_image_uncertainty_grid\n",
    "from src.utils.environment import get_device, set_seed, load_pretrained_model\n",
    "import os\n",
    "\n",
    "# Since on a notebook we can have nicer bars\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345d2fb-62f0-4d0d-9cfb-12ca609dcba8",
   "metadata": {
    "id": "a345d2fb-62f0-4d0d-9cfb-12ca609dcba8"
   },
   "source": [
    "### ğŸ§ª Setup: Seed and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d158ca43-df3a-45a2-9e9d-47ced73866ff",
   "metadata": {
    "id": "d158ca43-df3a-45a2-9e9d-47ced73866ff"
   },
   "outputs": [],
   "source": [
    "seed = 1337\n",
    "set_seed(seed)\n",
    "device = get_device()\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cbc5f8-901d-466b-ad2a-9929037e20b0",
   "metadata": {
    "id": "d2cbc5f8-901d-466b-ad2a-9929037e20b0",
    "lines_to_next_cell": 0
   },
   "source": [
    "## ğŸ’¡ Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9b0a39-6cfe-48f1-8cd9-3a0114637c05",
   "metadata": {
    "id": "4e9b0a39-6cfe-48f1-8cd9-3a0114637c05"
   },
   "source": [
    "#### ğŸ› ï¸ Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b288654b-668c-4ce7-8f10-d862677e29e4",
   "metadata": {
    "id": "b288654b-668c-4ce7-8f10-d862677e29e4"
   },
   "outputs": [],
   "source": [
    "n_samples = 5\n",
    "save_dir = \"samples\"\n",
    "max_steps = 1000\n",
    "model_name = \"unet\"\n",
    "method = \"diffusion\"  # or \"flow\"\n",
    "ckpt_path = \"checkpoints/best_model.pth\"  # or use your last checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ba2dda",
   "metadata": {
    "id": "81ba2dda"
   },
   "source": [
    "#### Define Class for QUDiffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e636f678-c6b3-4ad4-ba4a-2073b818a5c2",
   "metadata": {
    "id": "e636f678-c6b3-4ad4-ba4a-2073b818a5c2"
   },
   "outputs": [],
   "source": [
    "\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "\n",
    "\n",
    "class UQDiffusion(Diffusion):\n",
    "    \"\"\"\n",
    "    Diffusion model with uncertainty estimation capabilities.\n",
    "    Extends the base Diffusion class to support Laplace approximation models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def sample_from_gaussian(self, mean: Tensor, var: Tensor) -> Tensor:\n",
    "        \"\"\"Sample from Gaussian distribution with given mean and variance.\"\"\"\n",
    "        std = torch.sqrt(torch.clamp(var, min=1e-8))\n",
    "        return mean + std * torch.randn_like(mean)\n",
    "\n",
    "    def perform_training_step(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        x_0: Tensor,\n",
    "        y: Optional[Tensor] = None,\n",
    "        t: Optional[Tensor] = None,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Override to use accurate_forward during training if available.\"\"\"\n",
    "        x_0 = x_0.to(self.device)\n",
    "        if t is None:\n",
    "            t = self._sample_timesteps(x_0.size(0))\n",
    "        x_t, noise = self._sample_q(x_0, t)\n",
    "\n",
    "        noise_pred = model(x_t, t, y=y)\n",
    "\n",
    "        return self.loss_simple(noise, noise_pred)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_step(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        x_t: Tensor,\n",
    "        t: Tensor,\n",
    "        y: Optional[Tensor] = None,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Override sample_step to optionally include uncertainty.\n",
    "        \"\"\"\n",
    "        return self._sample_step_with_uncertainty(model, x_t, t, y)\n",
    "\n",
    "    def _sample_step_with_uncertainty(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        x_t: Tensor,\n",
    "        t: Tensor,\n",
    "        y: Optional[Tensor] = None,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Sampling step with uncertainty estimation.\n",
    "        NOTE: we never used this function, dunno if it works or makes sense in any way\n",
    "              probably it can be deleted\n",
    "\n",
    "        \"\"\"\n",
    "        # NOTE: TO REVIEW\n",
    "        beta_t = self.beta[t].view(-1, 1, 1, 1)\n",
    "        alpha_t = self.alpha[t].view(-1, 1, 1, 1)\n",
    "        alpha_bar_t = self.alpha_bar[t].view(-1, 1, 1, 1)\n",
    "\n",
    "        # Get noise prediction with uncertainty\n",
    "        noise_pred, noise_var = model(x_t, t, y=y)\n",
    "\n",
    "        # Standard diffusion coefficients\n",
    "        coef1 = 1.0 / alpha_t.sqrt()\n",
    "        coef2 = (1.0 - alpha_t) / (1.0 - alpha_bar_t).sqrt()\n",
    "\n",
    "        # Compute mean of x_prev\n",
    "        x_prev_mean = coef1 * (x_t - coef2 * noise_pred)\n",
    "\n",
    "        # Add scheduled noise\n",
    "        if t[0] > 1:\n",
    "            scheduled_noise = torch.randn_like(x_t) * beta_t.sqrt()\n",
    "        else:\n",
    "            scheduled_noise = torch.zeros_like(x_t)\n",
    "\n",
    "        x_prev = x_prev_mean + scheduled_noise\n",
    "        return x_prev\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def monte_carlo_covariance_estim(\n",
    "        self,\n",
    "        x_mean: Tensor,\n",
    "        x_var: Tensor,\n",
    "        eps_mean: Tensor,\n",
    "        eps_var: Tensor,\n",
    "        S: int = 10,\n",
    "    ) -> Tuple[Tensor, Tensor]:\n",
    "        \"\"\"\n",
    "        Perform Monte Carlo sampling to estimate covariance matrix.\n",
    "        Args:\n",
    "            mean_x0: Mean of x_0 estimated by diffusion.\n",
    "            var_x0: Variance of x_0 estimated by propagation.\n",
    "            S: Number of Monte Carlo samples.\n",
    "\n",
    "        Returns:\n",
    "            mc_mean: Empirical mean of samples.\n",
    "            mc_var: Empirical pixel-wise variance of samples.\n",
    "        \"\"\"\n",
    "\n",
    "        std_x = torch.sqrt(torch.clamp(x_var, min=1e-8))\n",
    "        x_samples = [x_mean + std_x * torch.randn_like(x_mean) for _ in range(S)]\n",
    "\n",
    "        std_eps = torch.sqrt(torch.clamp(eps_var, min=1e-8))\n",
    "        eps_samples = [eps_mean + std_eps * torch.randn_like(eps_mean) for _ in range(S)]\n",
    "\n",
    "        x_samples = torch.stack(x_samples, dim=0)  # [S, B, C, H, W]\n",
    "        eps_samples = torch.stack(eps_samples, dim=0)  # [S, B, C, H, W]\n",
    "\n",
    "        first_term = 1/S * torch.sum(x_samples * eps_samples, dim=0) # [B, C, H, W]\n",
    "        second_term = x_mean * (1/S * torch.sum(eps_samples, dim=0)) # [B, C, H, W]\n",
    "\n",
    "        return first_term - second_term\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_with_uncertainty(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        t_sample_times: Optional[List[int]] = None,\n",
    "        channels: int = 1,\n",
    "        log_intermediate: bool = True,\n",
    "        y: Optional[Tensor] = None,\n",
    "        cov_num_sample: int = 10,\n",
    "    ) -> Tuple[List[Tensor], List[Tensor], Optional[List[Tensor]]]:\n",
    "        \"\"\"\n",
    "        Iteratively sample from the model, tracking predictive uncertainty and optionally Cov(x, Îµ).\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        batch_size = 1 if y is None else y.size(0)\n",
    "\n",
    "        x_t = torch.randn(batch_size, channels, self.img_size, self.img_size, device=self.device)\n",
    "        x_t_mean = x_t.clone()\n",
    "        x_t_var = torch.zeros_like(x_t)\n",
    "        cov_t = torch.zeros_like(x_t)\n",
    "\n",
    "        intermediates, uncertainties = [], []\n",
    "\n",
    "        for i in reversed(range(self.noise_steps)):\n",
    "            t = torch.full((batch_size,), i, device=self.device, dtype=torch.long)\n",
    "\n",
    "            # Predict noise and its variance\n",
    "            eps_mean, eps_var = model(x_t, t, y=y)  #mean and variance of noise\n",
    "\n",
    "            # Compute xt-1\n",
    "            beta_t = self.beta[t].view(-1, 1, 1, 1)\n",
    "            alpha_t = self.alpha[t].view(-1, 1, 1, 1)\n",
    "            alpha_bar_t = self.alpha_bar[t].view(-1, 1, 1, 1)\n",
    "\n",
    "            # Mean and x_t-1\n",
    "            coef1 = 1.0 / alpha_t.sqrt()\n",
    "            coef2 = (1.0 - alpha_t) / (1.0 - alpha_bar_t).sqrt()\n",
    "            x_prev_mean = coef1 * (x_t_mean - coef2 * eps_mean)\n",
    "            x_prev = coef1 * (x_t - coef2 * eps_mean) + torch.randn_like(x_t) * beta_t.sqrt()\n",
    "\n",
    "            # Variance\n",
    "            coef3 = 2 * beta_t / (1 - alpha_bar_t).sqrt()\n",
    "            coef4 = beta_t**2 / (1 - alpha_bar_t)\n",
    "            x_prev_var = coef1 * (x_t_var - coef3 * cov_t + coef4 * eps_var) + beta_t\n",
    "\n",
    "\n",
    "            # Covariance estimation with Monte Carlo\n",
    "            covariance = self.monte_carlo_covariance_estim(\n",
    "                x_prev_mean,\n",
    "                x_prev_var,\n",
    "                eps_mean,\n",
    "                eps_var,\n",
    "                S=cov_num_sample,\n",
    "            )\n",
    "\n",
    "            # Log intermediate images\n",
    "            if log_intermediate and t_sample_times and i in t_sample_times:\n",
    "                intermediates.append(self.transform_sampled_image(x_t.clone()))\n",
    "                uncertainties.append(x_t_var.clone().cpu())  # per-pixel variance\n",
    "\n",
    "            x_t = x_prev\n",
    "            x_t_mean = x_prev_mean\n",
    "            x_t_var = x_prev_var\n",
    "            cov_t = covariance\n",
    "\n",
    "\n",
    "        uncertainties = torch.stack(uncertainties)  # [num_steps, B, C, H, W]\n",
    "\n",
    "        model.train()\n",
    "        return intermediates, uncertainties\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        t_sample_times: Optional[List[int]] = None,\n",
    "        channels: int = 1,\n",
    "        log_intermediate: bool = False,\n",
    "        y: Optional[Tensor] = None,\n",
    "    ) -> Tuple[List[Tensor], List[Tensor]]:\n",
    "        \"\"\"\n",
    "        Override sample method to optionally use uncertainty.\n",
    "\n",
    "        If uncertainty_schedule is provided, uses uncertainty sampling,\n",
    "        otherwise falls back to deterministic sampling for backward compatibility.\n",
    "        \"\"\"\n",
    "        intermediates, _, _ = self.sample_with_uncertainty(\n",
    "            model=model,\n",
    "            t_sample_times=t_sample_times,\n",
    "            channels=channels,\n",
    "            log_intermediate=log_intermediate,\n",
    "            y=y,\n",
    "        )\n",
    "        return intermediates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f986a39",
   "metadata": {
    "id": "9f986a39"
   },
   "source": [
    "### ğŸ’ª Fit Laplace approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "P62LzRyaxfBn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P62LzRyaxfBn",
    "outputId": "66dadf0e-a32e-4c2e-b344-2611d4a4a891"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to write /Users/jaczac/.config/netrc/netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "                                                                                                                                                                                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Laplace fitting completed on last layer of the diffusion model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from src.models.llla_model import LaplaceApproxModel\n",
    "from src.utils.data import get_llla_dataloader\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "# Load pretrained MAP model using best checkpoint\n",
    "diff_model = load_pretrained_model(\n",
    "    model_name=\"unet\",\n",
    "    ckpt_path=\"jac-zac/diffusion-project/best-model:v22\",\n",
    "    device=device,\n",
    "    model_kwargs={\"num_classes\": num_classes, \"time_emb_dim\": 128},\n",
    "    use_wandb=True,\n",
    ")\n",
    "\n",
    "# 2ï¸âƒ£ Prepare data loaders for the Laplace fit\n",
    "train_loader, _ = get_llla_dataloader(batch_size=128)\n",
    "\n",
    "# WARNING: This is currently wrong I have to use the Diffusion class perhaps\n",
    "# to return a dataloader with images with noise or somehow use directly the functions inside diffusion\n",
    "\n",
    "# Wrap diffusion model with your Custom Model for Laplace last layer approx\n",
    "# NOTE: Automatically call fit\n",
    "laplace_model = LaplaceApproxModel(diff_model, train_loader, args=None, config=None)\n",
    "\n",
    "print(\"Laplace fitting completed on last layer of the diffusion model.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b667cd2",
   "metadata": {
    "id": "3b667cd2",
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "<!-- #region id=\"1d2b6a2d\" -->\n",
    "### ğŸ’¨ Initialize Diffusion Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2b6a2d",
   "metadata": {},
   "source": [
    "<!-- #endregion -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4a65f99e",
   "metadata": {
    "id": "4a65f99e",
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Initialize uncertainty-aware diffusion (same interface as base class)\n",
    "diffusion = UQDiffusion(img_size=28, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "n_gIwbObJxDW",
   "metadata": {
    "id": "n_gIwbObJxDW"
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def plot_image_uncertainty_grid(\n",
    "    model,\n",
    "    method_instance,\n",
    "    n: int,\n",
    "    num_intermediate: int,\n",
    "    max_steps: int,\n",
    "    save_dir: str,\n",
    "    device: torch.device,\n",
    "    num_classes: int,\n",
    "    cov_num_sample: int = 50,\n",
    "    uq_cmp: str = \"grey\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate and plot a grid of intermediate samples for either diffusion or flow.\n",
    "\n",
    "    Args:\n",
    "        model: The trained model.\n",
    "        method_instance: The sampling method instance (Diffusion or FlowMatching).\n",
    "        n (int): Number of classes from which to generate ([0,1,..,n-1]).\n",
    "        num_intermediate (int): Number of intermediate steps to visualize.\n",
    "        max_steps (int): Maximum number of steps or timesteps.\n",
    "        save_dir (str): Directory to save the output image.\n",
    "        device: Torch device.\n",
    "        num_classes (int): Number of classes for label conditioning.\n",
    "    \"\"\"\n",
    "    # Prepare conditioning labels\n",
    "    y = torch.arange(n, device=device) % num_classes\n",
    "\n",
    "    # Decide which type of timesteps to generate\n",
    "    # if method_instance.__class__.__name__ == \"FlowMatching\":\n",
    "    #     # Flow matching: choose indices between 0 and (steps-1)\n",
    "    #     step_indices = torch.linspace(\n",
    "    #         0, max_steps - 1, steps=num_intermediate, dtype=torch.int32\n",
    "    #     ).tolist()\n",
    "\n",
    "    #     all_samples_grouped = method_instance.sample(\n",
    "    #         model,\n",
    "    #         steps=max_steps,\n",
    "    #         log_intermediate=True,\n",
    "    #         t_sample_times=step_indices,\n",
    "    #         y=y,\n",
    "    #     )\n",
    "    #     timesteps = step_indices\n",
    "    # else:\n",
    "        # Diffusion: choose timesteps between max_steps and 0\n",
    "    t_sample_times = torch.linspace(\n",
    "        max_steps-1,\n",
    "        0,\n",
    "        steps=num_intermediate,\n",
    "        dtype=torch.int32,\n",
    "    ).tolist()\n",
    "    print(\"sample times\", t_sample_times)\n",
    "\n",
    "    all_samples_grouped, uncertainties = method_instance.sample_with_uncertainty(\n",
    "        model,\n",
    "        t_sample_times=t_sample_times,\n",
    "        log_intermediate=True,\n",
    "        y=y,\n",
    "        cov_num_sample=cov_num_sample,\n",
    "    )\n",
    "    timesteps = t_sample_times\n",
    "\n",
    "    ### ------------------ Plot images grid ------------------ ###\n",
    "\n",
    "    # Stack all generated images into a (B, T, C, H, W) tensor\n",
    "    stacked = torch.stack(all_samples_grouped)  # (T, B, C, H, W)\n",
    "    permuted = stacked.permute(1, 0, 2, 3, 4)  # (B, T, C, H, W)\n",
    "    num_samples, num_timesteps = permuted.shape[:2]   # extract B and T\n",
    "    print(\"num timesteps\", num_timesteps)\n",
    "\n",
    "    # Save as a grid\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    out_path_img = os.path.join(save_dir, \"all_samples_grid.png\")\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        num_samples, num_intermediate, figsize=(1.5 * num_intermediate, 1.5 * num_samples)\n",
    "    )\n",
    "\n",
    "    if num_samples == 1:\n",
    "        axes = np.expand_dims(axes, 0)\n",
    "    if num_intermediate == 1:\n",
    "        axes = np.expand_dims(axes, 1)\n",
    "\n",
    "    indices = np.linspace(0, num_timesteps - 1, num=num_intermediate, dtype=int)\n",
    "\n",
    "    for row in range(num_samples):\n",
    "        for idx, col in enumerate(indices):\n",
    "            img = permuted[row, col].squeeze().cpu().numpy()\n",
    "            ax = axes[row, col]\n",
    "            ax.imshow(img, cmap=\"gray\")\n",
    "            ax.axis(\"off\")\n",
    "            if row == 0:\n",
    "                ax.set_title(f\"step={timesteps[col]}\", fontsize=10)\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(f\"Sample {row+1}\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path_img, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    ### ------------------ Plot uncertainties grid ------------------ ###\n",
    "\n",
    "    # Convert uncertainties to tensor if needed\n",
    "    if isinstance(uncertainties, list):\n",
    "        uncertainties = torch.stack(uncertainties)  # (T, B, C, H, W)\n",
    "\n",
    "    # Ensure uncertainties has same ordering: (B, T, C, H, W)\n",
    "    uncertainties_permuted = uncertainties.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "    out_path_unc = os.path.join(save_dir, \"all_uncertainties_grid.png\")\n",
    "\n",
    "    fig, axes = plt.subplots(\n",
    "        num_samples, num_intermediate, figsize=(1.5 * num_intermediate, 1.5 * num_samples)\n",
    "    )\n",
    "\n",
    "    if num_samples == 1:\n",
    "        axes = np.expand_dims(axes, 0)\n",
    "    if num_intermediate == 1:\n",
    "        axes = np.expand_dims(axes, 1)\n",
    "\n",
    "    for row in range(num_samples):\n",
    "        for col in range(num_intermediate):\n",
    "            unc = uncertainties_permuted[row, col].squeeze().cpu().numpy()\n",
    "            ax = axes[row, col]\n",
    "            im = ax.imshow(unc, cmap=uq_cmp)  # Heatmap for uncertainty\n",
    "            ax.axis(\"off\")\n",
    "            if row == 0:\n",
    "                ax.set_title(f\"step={timesteps[col]}\", fontsize=10)\n",
    "            if col == 0:\n",
    "                ax.set_ylabel(f\"Sample {row+1}\", fontsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path_unc, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    return all_samples_grouped, uncertainties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xnCp4gh00K1R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xnCp4gh00K1R",
    "outputId": "c0ca0973-b4fa-4dc5-d1ee-269b49e11305"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample times [999, 946, 893, 841, 788, 736, 683, 630, 578, 525, 473, 420, 368, 315, 262, 210, 157, 105, 52, 0]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "num_intermediate = 20\n",
    "\n",
    "all_samples_grouped, uncertainties = plot_image_uncertainty_grid(\n",
    "        laplace_model,\n",
    "        diffusion,\n",
    "        num_intermediate=num_intermediate,\n",
    "        n=1,\n",
    "        max_steps=max_steps,\n",
    "        save_dir=save_dir,\n",
    "        device=device,\n",
    "        num_classes=num_classes,\n",
    "        cov_num_sample=100,\n",
    "    )\n",
    "\n",
    "\n",
    "# Display samples grid\n",
    "out_path_img = os.path.join(save_dir, \"all_samples_grid.png\")\n",
    "display(Image.open(out_path_img))\n",
    "\n",
    "# Display uncertainties grid\n",
    "out_path_unc = os.path.join(save_dir, \"all_uncertainties_grid.png\")\n",
    "display(Image.open(out_path_unc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ef0cf-0af7-4ac3-8ea0-e61b962cd036",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uncertainties.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4e232-2bca-4ec8-9d32-d9d2773740e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# Sum over the last two dimensions (28x28)\n",
    "sums = uncertainties.sum(dim=[-1, -2])  # shape: [10, 1, 1]\n",
    "\n",
    "# Flatten to shape\n",
    "sums_flat = sums.view(num_intermediate)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(10), sums_flat.tolist(), marker='o', linestyle='-')\n",
    "plt.title(\"Sum of last two dimensions per item in first dimension\")\n",
    "plt.xlabel(\"Index in first dimension\")\n",
    "plt.ylabel(\"Sum over 28x28\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
