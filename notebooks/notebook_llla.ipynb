{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdefdf5-2a0a-4ca7-9672-7e1544aad8a1",
   "metadata": {
    "id": "1fdefdf5-2a0a-4ca7-9672-7e1544aad8a1"
   },
   "source": [
    "# 🧙‍♂️ Sample Generation with Pretrained Model + LLLA\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Jac-Zac/PML_DL_Final_Project/blob/master/notebooks/notebook_llla.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5LsZiP4Jfsqw",
   "metadata": {
    "id": "5LsZiP4Jfsqw"
   },
   "source": [
    "### Initial setup ⚙️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hjV2GS6MlwQP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hjV2GS6MlwQP",
    "outputId": "e6174ee0-185b-446f-e9a4-41f532c46d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Run, make sure you are inside 'PML_DL_Final_Project' with the latest updates (git pull).\n",
      "Moving to root directory to have correct access to all of the files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "repo_dir = \"PML_DL_Final_Project\"\n",
    "\n",
    "def in_colab():\n",
    "    # Colab sets this environment variable\n",
    "    return 'COLAB_GPU' in os.environ\n",
    "\n",
    "if in_colab():\n",
    "    # In Colab: clone repo if not present\n",
    "    if not os.path.exists(repo_dir):\n",
    "        !git clone https://github.com/Jac-Zac/PML_DL_Final_Project.git\n",
    "        os.chdir(repo_dir)\n",
    "        # Install requirements quietly\n",
    "        !pip install -r requirements.txt -q\n",
    "    else:\n",
    "        os.chdir(repo_dir)\n",
    "        print(f\"Repository '{repo_dir}' already exists. Skipping clone.\")\n",
    "else:\n",
    "    # Local: assume repo is already cloned\n",
    "    print(f\"Local Run, make sure you are inside '{repo_dir}' with the latest updates (git pull).\")\n",
    "    print(f\"Moving to root directory to have correct access to all of the files\")\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b0bc4-6bf5-40b0-8af7-5c30a02c1ada",
   "metadata": {
    "id": "064b0bc4-6bf5-40b0-8af7-5c30a02c1ada"
   },
   "source": [
    "### 📦 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f6b33e-bec1-47a2-afe0-c57ca840a622",
   "metadata": {
    "id": "31f6b33e-bec1-47a2-afe0-c57ca840a622"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.utils.data import get_dataloaders\n",
    "from src.models.diffusion import Diffusion\n",
    "from src.utils.plots import plot_image_grid\n",
    "from src.utils.environment import get_device, set_seed, load_pretrained_model\n",
    "\n",
    "# Since on a notebook we can have nicer bars\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345d2fb-62f0-4d0d-9cfb-12ca609dcba8",
   "metadata": {
    "id": "a345d2fb-62f0-4d0d-9cfb-12ca609dcba8"
   },
   "source": [
    "### 🧪 Setup: Seed and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d158ca43-df3a-45a2-9e9d-47ced73866ff",
   "metadata": {
    "id": "d158ca43-df3a-45a2-9e9d-47ced73866ff"
   },
   "outputs": [],
   "source": [
    "seed = 1337\n",
    "set_seed(seed)\n",
    "device = get_device()\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cbc5f8-901d-466b-ad2a-9929037e20b0",
   "metadata": {
    "id": "d2cbc5f8-901d-466b-ad2a-9929037e20b0",
    "lines_to_next_cell": 0
   },
   "source": [
    "## 💡 Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9b0a39-6cfe-48f1-8cd9-3a0114637c05",
   "metadata": {
    "id": "4e9b0a39-6cfe-48f1-8cd9-3a0114637c05"
   },
   "source": [
    "#### 🛠️ Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b288654b-668c-4ce7-8f10-d862677e29e4",
   "metadata": {
    "id": "b288654b-668c-4ce7-8f10-d862677e29e4"
   },
   "outputs": [],
   "source": [
    "n_samples = 5\n",
    "save_dir = \"samples\"\n",
    "max_steps = 1000\n",
    "model_name = \"unet\"\n",
    "method = \"diffusion\"  # or \"flow\"\n",
    "ckpt_path = \"checkpoints/best_model.pth\"  # or use your last checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b338dd8c-30ab-4e9a-bb50-86d89e8e13df",
   "metadata": {
    "id": "b338dd8c-30ab-4e9a-bb50-86d89e8e13df"
   },
   "source": [
    "#### 🔌 Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5918303f-edc6-4bdd-b312-76b4130ec052",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "5918303f-edc6-4bdd-b312-76b4130ec052",
    "outputId": "e043a595-0204-4563-8a1d-3a03cca6fbc2"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "num_classes = 10  # Total number of class labels (e.g., digits 0–9 for MNIST)\n",
    "\n",
    "model_kwargs = {\n",
    "    \"num_classes\": num_classes,\n",
    "    \"time_emb_dim\": 128,  # Must match training config\n",
    "}\n",
    "# Model name as expected by your `get_model` function\n",
    "model_name = \"unet\"\n",
    "ckpt_path = \"jac-zac/diffusion-project/best-model:v22\"\n",
    "\n",
    "# Load pretrained MAP model using best checkpoint\n",
    "# By default since I'm passing the path to an artifact it will use Wandb\n",
    "# Search there direcly via the API\n",
    "model = load_pretrained_model(\n",
    "    model_name=model_name,\n",
    "    ckpt_path=ckpt_path,\n",
    "    device=device,\n",
    "    model_kwargs=model_kwargs,\n",
    "    use_wandb=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ba2dda",
   "metadata": {},
   "source": [
    "#### Define Class for QUDiffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e636f678-c6b3-4ad4-ba4a-2073b818a5c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'artifact_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# List files in the artifact directory\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m files = os.listdir(\u001b[43martifact_dir\u001b[49m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFiles in artifact:\u001b[39m\u001b[33m\"\u001b[39m, files)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Assuming the checkpoint file is the first file\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'artifact_dir' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "\n",
    "\n",
    "class QUDiffusion(Diffusion):\n",
    "    \"\"\"\n",
    "    Diffusion model with uncertainty estimation capabilities.\n",
    "    Extends the base Diffusion class to support Laplace approximation models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def sample_from_gaussian(self, mean: Tensor, var: Tensor) -> Tensor:\n",
    "        \"\"\"Sample from Gaussian distribution with given mean and variance.\"\"\"\n",
    "        std = torch.sqrt(torch.clamp(var, min=1e-8))\n",
    "        return mean + std * torch.randn_like(mean)\n",
    "\n",
    "    def perform_training_step(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        x_0: Tensor,\n",
    "        y: Optional[Tensor] = None,\n",
    "        t: Optional[Tensor] = None,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Override to use accurate_forward during training if available.\"\"\"\n",
    "        x_0 = x_0.to(self.device)\n",
    "        if t is None:\n",
    "            t = self._sample_timesteps(x_0.size(0))\n",
    "        x_t, noise = self._sample_q(x_0, t)\n",
    "\n",
    "        noise_pred = model(x_t, t, y=y)\n",
    "\n",
    "        return self.loss_simple(noise, noise_pred)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_step(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        x_t: Tensor,\n",
    "        t: Tensor,\n",
    "        y: Optional[Tensor] = None,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Override sample_step to optionally include uncertainty.\n",
    "        \"\"\"\n",
    "        return self._sample_step_with_uncertainty(model, x_t, t, y)\n",
    "\n",
    "    def _sample_step_with_uncertainty(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        x_t: Tensor,\n",
    "        t: Tensor,\n",
    "        y: Optional[Tensor] = None,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Sampling step with uncertainty estimation.\"\"\"\n",
    "\n",
    "        # NOTE: TO REVIEW\n",
    "        beta_t = self.beta[t].view(-1, 1, 1, 1)\n",
    "        alpha_t = self.alpha[t].view(-1, 1, 1, 1)\n",
    "        alpha_bar_t = self.alpha_bar[t].view(-1, 1, 1, 1)\n",
    "\n",
    "        # Get noise prediction with uncertainty\n",
    "        noise_pred, noise_var = model(x_t, t, y=y)\n",
    "\n",
    "        # Standard diffusion coefficients\n",
    "        coef1 = 1.0 / alpha_t.sqrt()\n",
    "        coef2 = (1.0 - alpha_t) / (1.0 - alpha_bar_t).sqrt()\n",
    "\n",
    "        # Compute mean of x_prev\n",
    "        x_prev_mean = coef1 * (x_t - coef2 * noise_pred)\n",
    "\n",
    "        # Add scheduled noise\n",
    "        if t[0] > 1:\n",
    "            scheduled_noise = torch.randn_like(x_t) * beta_t.sqrt()\n",
    "        else:\n",
    "            scheduled_noise = torch.zeros_like(x_t)\n",
    "\n",
    "        x_prev = x_prev_mean + scheduled_noise\n",
    "        return x_prev\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_with_uncertainty(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        t_sample_times: Optional[List[int]] = None,\n",
    "        channels: int = 1,\n",
    "        log_intermediate: bool = False,\n",
    "        y: Optional[Tensor] = None,\n",
    "    ) -> Tuple[List[Tensor], List[Tensor]]:\n",
    "        \"\"\"\n",
    "        Sample with uncertainty estimation at specified timesteps.\n",
    "\n",
    "        Args:\n",
    "            model: LaplaceApproxModel instance\n",
    "            uncertainty_schedule: Boolean list indicating which timesteps to use uncertainty\n",
    "            t_sample_times: Timesteps to log intermediates\n",
    "            channels: Number of image channels\n",
    "            log_intermediate: Whether to log intermediate results\n",
    "            y: Conditional labels\n",
    "\n",
    "        Returns:\n",
    "            intermediates: List of generated samples\n",
    "            uncertainties: List of uncertainty estimates (if return_uncertainties=True)\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        batch_size = 1 if y is None else y.size(0)\n",
    "\n",
    "        # NOTE: TO REVIEW\n",
    "\n",
    "        # NOTE: Always use uncertainty or implement bayeskip\n",
    "        # Initialize uncertainty schedule if not provided\n",
    "        uncertainty_start = int(0 * self.noise_steps)\n",
    "        uncertainty_schedule = [i >= uncertainty_start for i in range(self.noise_steps)]\n",
    "\n",
    "        # Pad uncertainty schedule if too short\n",
    "        while len(uncertainty_schedule) < self.noise_steps:\n",
    "            uncertainty_schedule.append(False)\n",
    "\n",
    "        # Initialize sampling\n",
    "        x_t = torch.randn(\n",
    "            batch_size, channels, self.img_size, self.img_size, device=self.device\n",
    "        )\n",
    "\n",
    "        intermediates = []\n",
    "        uncertainties = []\n",
    "\n",
    "        # Track uncertainty for propagation\n",
    "        var_x_t = torch.zeros_like(x_t)\n",
    "\n",
    "        for i in reversed(range(self.noise_steps)):\n",
    "            t = torch.full((batch_size,), i, device=self.device, dtype=torch.long)\n",
    "            use_uncertainty = uncertainty_schedule[i]\n",
    "\n",
    "            # Perform sampling step\n",
    "            x_t = self.sample_step(model, x_t, t, y=y)\n",
    "\n",
    "            # Update uncertainty if tracking\n",
    "            if use_uncertainty and hasattr(model, \"forward\"):\n",
    "                # Get uncertainty estimate\n",
    "                with torch.no_grad():\n",
    "                    _, noise_var = model(x_t, t, y=y)\n",
    "                    if noise_var is not None:\n",
    "                        # Simple uncertainty propagation\n",
    "                        beta_t = self.beta[t].view(-1, 1, 1, 1)\n",
    "                        var_x_t = var_x_t + noise_var + beta_t\n",
    "                    else:\n",
    "                        var_x_t = var_x_t + self.beta[t].view(-1, 1, 1, 1)\n",
    "            else:\n",
    "                # Just add scheduled noise variance\n",
    "                var_x_t = var_x_t + self.beta[t].view(-1, 1, 1, 1)\n",
    "\n",
    "            # Store total uncertainty\n",
    "            uncertainties.append(var_x_t.sum(dim=(1, 2, 3)).cpu())\n",
    "\n",
    "            # Log intermediate if requested\n",
    "            if log_intermediate and t_sample_times and i in t_sample_times:\n",
    "                intermediates.append(self.transform_sampled_image(x_t.clone()))\n",
    "\n",
    "        # Add final sample\n",
    "        intermediates.append(self.transform_sampled_image(x_t))\n",
    "        model.train()\n",
    "\n",
    "        return intermediates, uncertainties\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        t_sample_times: Optional[List[int]] = None,\n",
    "        channels: int = 1,\n",
    "        log_intermediate: bool = False,\n",
    "        y: Optional[Tensor] = None,\n",
    "    ) -> Tuple[List[Tensor], List[Tensor]]:\n",
    "        \"\"\"\n",
    "        Override sample method to optionally use uncertainty.\n",
    "\n",
    "        If uncertainty_schedule is provided, uses uncertainty sampling,\n",
    "        otherwise falls back to deterministic sampling for backward compatibility.\n",
    "        \"\"\"\n",
    "        intermediates, uncertainties = self.sample_with_uncertainty(\n",
    "            model=model,\n",
    "            t_sample_times=t_sample_times,\n",
    "            channels=channels,\n",
    "            log_intermediate=log_intermediate,\n",
    "            y=y,\n",
    "        )\n",
    "        return intermediates, uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f986a39",
   "metadata": {
    "id": "9f986a39"
   },
   "source": [
    "### 💪 Fit Laplace approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d1afeeb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "6d1afeeb",
    "lines_to_next_cell": 0,
    "outputId": "6942d10a-a588-4a80-a613-8582005c300e"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     },
     "evalue": "No module named 'laplace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-7-464933973.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mllla_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLaplaceApproxModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Prepare data loaders for the Laplace fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/PML_DL_Final_Project/src/models/llla_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlaplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaselaplace\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiagLaplace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlaplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurvature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackPackEF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparameters_to_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'laplace'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from src.models.llla_model import LaplaceApproxModel\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "# Prepare data loaders for the Laplace fit\n",
    "train_loader, _ = get_dataloaders(batch_size=batch_size)\n",
    "\n",
    "# Wrap diffusion model with your CustomModel for Laplace last layer approx\n",
    "# This fits also the model by default\n",
    "laplace_model = LaplaceApproxModel(diff_model, train_loader, args=None, config=None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b667cd2",
   "metadata": {
    "id": "3b667cd2"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d2b6a2d",
   "metadata": {},
   "source": [
    "### 💨 Initialize Diffusion Process\n",
    "<!-- #endregion -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65f99e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 525
    },
    "id": "6d1afeeb",
    "lines_to_next_cell": 0,
    "outputId": "6942d10a-a588-4a80-a613-8582005c300e"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Initialize uncertainty-aware diffusion (same interface as base class)\n",
    "diffusion = QUDiffusion(img_size=28, device=device)\n",
    "\n",
    "# Works exactly like base Diffusion class\n",
    "samples = diffusion.sample(model=laplace_model)\n",
    "\n",
    "# Or get detailed uncertainty information\n",
    "samples, uncertainties = diffusion.sample_with_uncertainty(\n",
    "    model=laplace_model,\n",
    "    channels=3,\n",
    ")\n",
    "\n",
    "# Try to make some samples\n",
    "\n",
    "# NOTE: ADD A NEW FUNCTION FOR PLOT WITH UNCERTAINTY\n",
    "  # plot_image_grid(\n",
    "  # model,\n",
    "  # method_instance,\n",
    "  # num_intermediate=5,\n",
    "  # n=args.n,\n",
    "  # max_steps=args.max_steps,\n",
    "  # save_dir=args.save_dir,\n",
    "  # device=device,\n",
    "# num_classes=num_classes,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f09f7",
   "metadata": {
    "id": "3b667cd2"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
