{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdefdf5-2a0a-4ca7-9672-7e1544aad8a1",
   "metadata": {
    "id": "1fdefdf5-2a0a-4ca7-9672-7e1544aad8a1"
   },
   "source": [
    "# 🧙‍♂️ Sample Generation with Pretrained Model + LLLA\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Jac-Zac/PML_DL_Final_Project/blob/master/notebooks/notebook_llla_diff.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5LsZiP4Jfsqw",
   "metadata": {
    "id": "5LsZiP4Jfsqw"
   },
   "source": [
    "### Initial setup ⚙️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "MvAelYDxQPJO",
   "metadata": {
    "id": "MvAelYDxQPJO"
   },
   "outputs": [],
   "source": [
    "# !pip install laplace-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d346166f-906a-44cf-a38b-9b87a8ed2b40",
   "metadata": {
    "id": "d346166f-906a-44cf-a38b-9b87a8ed2b40"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c880eaf-d325-40af-8b9a-a965d417023e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c880eaf-d325-40af-8b9a-a965d417023e",
    "outputId": "33c95097-ba56-435e-8676-92f234de3937"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jaczac/Github/PML_DL_Final_Project\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "    import os\n",
    "\n",
    "    # !pip install laplace-torch -q\n",
    "    repo_dir = \"PML_DL_Final_Project\"\n",
    "\n",
    "    if not os.path.exists(repo_dir):\n",
    "        !git clone https://github.com/Jac-Zac/PML_DL_Final_Project.git\n",
    "    else:\n",
    "        print(f\"Repository '{repo_dir}' already exists. Skipping clone.\")\n",
    "\n",
    "\n",
    "    if os.path.isdir(repo_dir):\n",
    "        %cd $repo_dir\n",
    "        !pip install dotenv -q\n",
    "    else:\n",
    "        print(f\"Directory '{repo_dir}' not found. Please clone the repository first.\")\n",
    "\n",
    "else:\n",
    "    %cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064b0bc4-6bf5-40b0-8af7-5c30a02c1ada",
   "metadata": {
    "id": "064b0bc4-6bf5-40b0-8af7-5c30a02c1ada"
   },
   "source": [
    "### 📦 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f6b33e-bec1-47a2-afe0-c57ca840a622",
   "metadata": {
    "id": "31f6b33e-bec1-47a2-afe0-c57ca840a622"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.models.diffusion import Diffusion\n",
    "\n",
    "from src.utils.data import get_dataloaders\n",
    "from src.utils.plots import plot_image_grid, plot_image_uncertainty_grid\n",
    "from src.utils.environment import get_device, set_seed, load_pretrained_model\n",
    "import os\n",
    "\n",
    "# Since on a notebook we can have nicer bars\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a345d2fb-62f0-4d0d-9cfb-12ca609dcba8",
   "metadata": {
    "id": "a345d2fb-62f0-4d0d-9cfb-12ca609dcba8"
   },
   "source": [
    "### 🧪 Setup: Seed and Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d158ca43-df3a-45a2-9e9d-47ced73866ff",
   "metadata": {
    "id": "d158ca43-df3a-45a2-9e9d-47ced73866ff"
   },
   "outputs": [],
   "source": [
    "seed = 1337\n",
    "set_seed(seed)\n",
    "device = get_device()\n",
    "os.makedirs(\"checkpoints\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cbc5f8-901d-466b-ad2a-9929037e20b0",
   "metadata": {
    "id": "d2cbc5f8-901d-466b-ad2a-9929037e20b0",
    "lines_to_next_cell": 0
   },
   "source": [
    "## 💡 Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ba2dda",
   "metadata": {
    "id": "81ba2dda"
   },
   "source": [
    "#### Define Class for QUDiffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d53181c-556d-4bfb-9e43-5a59958e83d7",
   "metadata": {
    "id": "0d53181c-556d-4bfb-9e43-5a59958e83d7"
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional, Tuple\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "\n",
    "class UQDiffusion(Diffusion):\n",
    "    \"\"\"\n",
    "    Diffusion model with uncertainty estimation capabilities.\n",
    "    Extends the base Diffusion class to support Laplace approximation models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def perform_training_step(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        x_0: Tensor,\n",
    "        y: Optional[Tensor] = None,\n",
    "        t: Optional[Tensor] = None,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"Override to use accurate_forward during training if available.\"\"\"\n",
    "        x_0 = x_0.to(self.device)\n",
    "        if t is None:\n",
    "            t = self._sample_timesteps(x_0.size(0))\n",
    "        x_t, noise = self._sample_q(x_0, t)\n",
    "\n",
    "        noise_pred = model(x_t, t, y=y)\n",
    "\n",
    "        return self.loss_simple(noise, noise_pred)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def monte_carlo_covariance_estim(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        t: Tensor,\n",
    "        x_mean: Tensor,\n",
    "        x_var: Tensor,\n",
    "        S: int = 10,\n",
    "        y: Optional[Tensor] = None,\n",
    "    ) -> Tensor:\n",
    "        \"\"\"\n",
    "        Perform Monte Carlo sampling to estimate covariance matrix.\n",
    "        Args:\n",
    "            mean_x0: Mean of x_0 estimated by diffusion.\n",
    "            var_x0: Variance of x_0 estimated by propagation.\n",
    "            S: Number of Monte Carlo samples.\n",
    "\n",
    "        Returns:\n",
    "            mc_mean: Empirical mean of samples.\n",
    "            mc_var: Empirical pixel-wise variance of samples.\n",
    "        \"\"\"\n",
    "        std_x = torch.sqrt(torch.clamp(x_var, min=1e-8))\n",
    "        x_samples = [x_mean + std_x * torch.randn_like(x_mean) for _ in range(S)]\n",
    "        eps = [model.accurate_forward(x_i, t, y=y) for x_i in x_samples]\n",
    "\n",
    "        x_samples = torch.stack(x_samples, dim=0)  # [S, B, C, H, W]\n",
    "        eps = torch.stack(eps, dim=0)  # [S, B, C, H, W]\n",
    "\n",
    "        first_term = torch.mean(x_samples * eps, dim=0)  # [B, C, H, W]\n",
    "        second_term = x_mean * torch.mean(eps, dim=0)  # [B, C, H, W]\n",
    "\n",
    "        return first_term - second_term\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample_with_uncertainty(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        t_sample_times: Optional[List[int]] = None,\n",
    "        channels: int = 1,\n",
    "        log_intermediate: bool = True,\n",
    "        y: Optional[Tensor] = None,\n",
    "        cov_num_sample: int = 10,\n",
    "    ) -> Tuple[List[Tensor], Tensor]:\n",
    "        \"\"\"\n",
    "        Iteratively sample from the model, tracking predictive uncertainty and optionally Cov(x, ε).\n",
    "        \"\"\"\n",
    "        model.eval()\n",
    "        batch_size = 1 if y is None else y.size(0)\n",
    "\n",
    "        x_t = torch.randn(\n",
    "            batch_size, channels, self.img_size, self.img_size, device=self.device\n",
    "        )\n",
    "\n",
    "        x_t_mean = x_t.clone()\n",
    "        x_t_var = torch.zeros_like(x_t)\n",
    "        cov_t = torch.zeros_like(x_t)\n",
    "\n",
    "        intermediates, uncertainties = [], []\n",
    "\n",
    "        for i in reversed(range(self.noise_steps)):\n",
    "            t = torch.full((batch_size,), i, device=self.device, dtype=torch.long)\n",
    "\n",
    "            # Predict noise and its variance\n",
    "            eps_mean, eps_var = model(x_t, t, y=y)  # mean and variance of noise\n",
    "            eps_t = eps_mean + torch.sqrt(eps_var) * torch.randn_like(eps_mean)\n",
    "\n",
    "            # Compute xt-1\n",
    "            beta_t = self.beta[t].view(-1, 1, 1, 1)\n",
    "            alpha_t = self.alpha[t].view(-1, 1, 1, 1)\n",
    "            alpha_bar_t = self.alpha_bar[t].view(-1, 1, 1, 1)\n",
    "\n",
    "            # Mean and x_t-1\n",
    "            coef1 = 1.0 / alpha_t.sqrt()\n",
    "            coef2 = (1.0 - alpha_t) / (1.0 - alpha_bar_t).sqrt()\n",
    "            x_prev_mean = coef1 * (x_t_mean - coef2 * eps_mean)\n",
    "            x_prev = (\n",
    "                coef1 * (x_t - coef2 * eps_t) + torch.randn_like(x_t) * beta_t.sqrt()\n",
    "            )\n",
    "\n",
    "            # Variance\n",
    "            coef3 = 2 * (1 - alpha_t) / alpha_t * (1 - alpha_bar_t).sqrt()\n",
    "            coef4 = (1 - alpha_t)**2 / alpha_t * (1 - alpha_bar_t)\n",
    "            x_prev_var = (\n",
    "                (1 / alpha_t * x_t_var) - (coef3 * cov_t) + (coef4 * eps_var) + beta_t\n",
    "                # (1 / alpha_t * x_t_var) + (coef4 * eps_var) + beta_t\n",
    "            )\n",
    "\n",
    "            if i > 0:\n",
    "                # Covariance estimation with Monte Carlo\n",
    "                covariance = self.monte_carlo_covariance_estim(\n",
    "                    model=model,\n",
    "                    t=t - 1,\n",
    "                    x_mean=x_prev_mean,\n",
    "                    x_var=x_prev_var,\n",
    "                    S=cov_num_sample,\n",
    "                    y=y,\n",
    "                )\n",
    "\n",
    "            if i % 100 == 0 or i == self.noise_steps - 1:\n",
    "                print(f\"\\nStep {i}\")\n",
    "                print(f\"  eps_var mean: {eps_var.mean().item():.4e}, std: {eps_var.std().item():.4e}\")\n",
    "                if i > 0:\n",
    "                    print(f\"  Covariance mean: {covariance.mean().item():.4e}, std: {covariance.std().item():.4e}\")\n",
    "                print(f\"  x_t_var mean: {x_t_var.mean().item():.4e}, std: {x_t_var.std().item():.4e}\")\n",
    "                print(f\"  x_prev_var mean: {x_prev_var.mean().item():.4e}, std: {x_prev_var.std().item():.4e}\")\n",
    "\n",
    "\n",
    "            # Log intermediate images\n",
    "            if log_intermediate and t_sample_times and i in t_sample_times:\n",
    "                intermediates.append(self.transform_sampled_image(x_t.clone()))\n",
    "                uncertainties.append(x_t_var.clone().cpu())  # per-pixel variance\n",
    "\n",
    "            x_t = x_prev\n",
    "            x_t_mean = x_prev_mean\n",
    "            x_t_var = x_prev_var\n",
    "            cov_t = covariance\n",
    "\n",
    "        uncertainties = torch.stack(uncertainties)  # [num_steps, B, C, H, W]\n",
    "\n",
    "        model.train()\n",
    "        return intermediates, uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9b0a39-6cfe-48f1-8cd9-3a0114637c05",
   "metadata": {
    "id": "4e9b0a39-6cfe-48f1-8cd9-3a0114637c05"
   },
   "source": [
    "#### 🛠️ Configuration Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b288654b-668c-4ce7-8f10-d862677e29e4",
   "metadata": {
    "id": "b288654b-668c-4ce7-8f10-d862677e29e4"
   },
   "outputs": [],
   "source": [
    "n_samples = 5\n",
    "save_dir = \"samples\"\n",
    "model_name = \"unet\"\n",
    "method = \"diffusion\"  # or \"flow\"\n",
    "ckpt_path = \"checkpoints/best_model.pth\"  # or use your last checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f986a39",
   "metadata": {
    "id": "9f986a39"
   },
   "source": [
    "### 💪 Fit Laplace approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cdf8b5f-d8df-46b9-bb5f-cf0a5e7dd648",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P62LzRyaxfBn",
    "outputId": "edbb2167-eb45-4742-be8e-65bb5bdc4451"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Unable to write /Users/jaczac/.config/netrc/netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjacopozac\u001b[0m (\u001b[33mjac-zac\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n",
      "                                                                                                                                                                                    "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     28\u001b[39m mnist_config.data.image_size = \u001b[32m28\u001b[39m  \u001b[38;5;66;03m# MNIST image size\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m#mnist_config.mode = \"flow\"\u001b[39;00m\n\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Wrap diffusion model with your Custom Model for Laplace last layer approx\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# NOTE: Automatically call fit\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m laplace_model = \u001b[43mLaplaceApproxModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiff_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmnist_config\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLaplace fitting completed on last layer of the diffusion model.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/PML_DL_Final_Project/src/models/llla_model.py:43\u001b[39m, in \u001b[36mLaplaceApproxModel.__init__\u001b[39m\u001b[34m(self, diff_model, dataloader, args, config)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28mself\u001b[39m.conv_out_la = DiagLaplace(\n\u001b[32m     31\u001b[39m     nn.Sequential(\n\u001b[32m     32\u001b[39m         \u001b[38;5;28mself\u001b[39m.conv_out, nn.Flatten(\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m     39\u001b[39m     backend=BackPackEF,  \u001b[38;5;66;03m# Curvature estimator backend\u001b[39;00m\n\u001b[32m     40\u001b[39m )\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Fit the Laplace approximation using the training data\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Github/PML_DL_Final_Project/src/models/llla_model.py:84\u001b[39m, in \u001b[36mLaplaceApproxModel.fit\u001b[39m\u001b[34m(self, train_loader, override)\u001b[39m\n\u001b[32m     81\u001b[39m \u001b[38;5;28mself\u001b[39m.conv_out_la.model.zero_grad()\n\u001b[32m     83\u001b[39m \u001b[38;5;66;03m# Move batch to the appropriate device\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m x_t, t, pred, y = [\u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m (x_t, t, pred, y)]\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     87\u001b[39m     feats = \u001b[38;5;28mself\u001b[39m.feature_extractor(x_t, t, y=y)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from src.models.llla_model import LaplaceApproxModel\n",
    "from src.utils.data import get_llla_dataloader\n",
    "from types import SimpleNamespace\n",
    "\n",
    "num_classes = 10\n",
    "model_kwargs = {\n",
    "    \"num_classes\": num_classes,\n",
    "    \"time_emb_dim\": 128,\n",
    "    # NOTE: Change time embedding to learned for flow which is more sensible\n",
    "    \"time_embedding_type\": \"mlp\" if method == \"flow\" else \"sinusoidal\",\n",
    "}\n",
    "\n",
    "\n",
    "# Load pretrained MAP model using best checkpoint\n",
    "diff_model = load_pretrained_model(\n",
    "    model_name=\"unet\",\n",
    "    ckpt_path=\"jac-zac/diffusion-project/best-model:v80\",\n",
    "    device=device,\n",
    "    model_kwargs=model_kwargs,\n",
    "    use_wandb=True,\n",
    ")\n",
    "\n",
    "# 2️⃣ Prepare data loaders for the Laplace fit\n",
    "train_loader, _ = get_llla_dataloader(batch_size=128, mode = \"diffusion\")\n",
    "\n",
    "mnist_config = SimpleNamespace()\n",
    "mnist_config.data = SimpleNamespace()\n",
    "mnist_config.data.image_size = 28  # MNIST image size\n",
    "#mnist_config.mode = \"flow\"\n",
    "\n",
    "# Wrap diffusion model with your Custom Model for Laplace last layer approx\n",
    "# NOTE: Automatically call fit\n",
    "laplace_model = LaplaceApproxModel(\n",
    "    diff_model, train_loader, args=None, config=mnist_config\n",
    ")\n",
    "\n",
    "print(\"Laplace fitting completed on last layer of the diffusion model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b667cd2",
   "metadata": {
    "id": "3b667cd2",
    "lines_to_next_cell": 0
   },
   "source": [
    "\n",
    "<!-- #region id=\"1d2b6a2d\" -->\n",
    "### 💨 Initialize Diffusion Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a65f99e",
   "metadata": {
    "id": "4a65f99e",
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Initialize uncertainty-aware diffusion (same interface as base class)\n",
    "diffusion = UQDiffusion(img_size=28, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95261ad0-4cd1-424d-9874-f791b9a67568",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95261ad0-4cd1-424d-9874-f791b9a67568",
    "outputId": "9c8d382b-1906-4927-aab4-52a0af1d580d"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "num_intermediate = 15\n",
    "total_steps = 1000\n",
    "\n",
    "all_samples_grouped, uncertainties = plot_image_uncertainty_grid(\n",
    "        laplace_model,\n",
    "        diffusion,\n",
    "        num_intermediate=num_intermediate,\n",
    "        n=1,\n",
    "        total_steps=total_steps,\n",
    "        save_dir=save_dir,\n",
    "        device=device,\n",
    "        num_classes=num_classes,\n",
    "        cov_num_sample=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f02271-7865-48b4-93f1-808d621b7a1c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "f4f02271-7865-48b4-93f1-808d621b7a1c",
    "outputId": "c73c359b-a4f6-48ec-9d8e-fd48c2a63464"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Display samples grid\n",
    "out_path_img = os.path.join(save_dir, \"all_samples_grid.png\")\n",
    "display(Image.open(out_path_img))\n",
    "\n",
    "# Display uncertainties grid\n",
    "out_path_unc = os.path.join(save_dir, \"all_uncertainties_grid.png\")\n",
    "display(Image.open(out_path_unc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711ef0cf-0af7-4ac3-8ea0-e61b962cd036",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "711ef0cf-0af7-4ac3-8ea0-e61b962cd036",
    "outputId": "bdcb5953-4379-4b78-eaed-78753f04c7dc"
   },
   "outputs": [],
   "source": [
    "print(uncertainties.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf4e232-2bca-4ec8-9d32-d9d2773740e4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "0bf4e232-2bca-4ec8-9d32-d9d2773740e4",
    "outputId": "d3410b95-30bb-4a30-cf3c-df1889ffa392"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "# Sum over the last two dimensions (28x28)\n",
    "sums = uncertainties.sum(dim=[-1, -2])  # shape: [10, 1, 1]\n",
    "\n",
    "# Flatten to shape\n",
    "sums_flat = sums.view(num_intermediate)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(range(num_intermediate), sums_flat.tolist(), marker='o', linestyle='-')\n",
    "plt.title(\"Sum of last two dimensions per item in first dimension\")\n",
    "plt.xlabel(\"Index in first dimension\")\n",
    "plt.ylabel(\"Sum over 28x28\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
